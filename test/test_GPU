import torch
import sys
import subprocess
import pynvml

def get_nvidia_driver_version():
    """é€é nvidia-smi ç²å–é©…å‹•ç‰ˆæœ¬"""
    try:
        output = subprocess.check_output(["nvidia-smi", "--query-gpu=driver_version", "--format=csv,noheader,nounits"])
        return output.decode().strip()
    except:
        return None

def check_hardware():
    print("="*60)
    print(f"ğŸ Python ç‰ˆæœ¬: {sys.version.split()[0]}")
    print(f"ğŸ”¥ PyTorch ç‰ˆæœ¬: {torch.__version__}")
    
    # ç²å–ç³»çµ±è³‡è¨Š
    cuda_available = torch.cuda.is_available()
    driver_version = get_nvidia_driver_version()
    
    print(f"ğŸš€ PyTorch CUDA å¯ç”¨æ€§: {'âœ… æ˜¯' if cuda_available else 'âŒ å¦'}")
    
    if cuda_available:
        current_device = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(current_device)
        print(f"ğŸ’» åµæ¸¬åˆ° GPU å‹è™Ÿ: {gpu_name}")
        
        # é¡¯å­˜è³‡è¨Š
        try:
            pynvml.nvmlInit()
            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            info = pynvml.nvmlDeviceGetMemoryInfo(handle)
            print(f"ğŸ“Š é¡¯å­˜ç‹€æ…‹: å·²ç”¨ {info.used // 1024**2}MB / ç¸½é‡ {info.total // 1024**2}MB")
            pynvml.nvmlShutdown()
        except:
            pass
    else:
        print("\nğŸ” è¨ºæ–·åˆ†æï¼š")
        
        # ç‹€æ³ 1: æ ¹æœ¬æ²’è£ NVIDIA é©…å‹•
        if driver_version is None:
            print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° NVIDIA é©…å‹•ç¨‹å¼ã€‚")
            print("ğŸ’¡ å»ºè­°ï¼šè«‹å» NVIDIA å®˜ç¶²ä¸‹è¼‰ä¸¦å®‰è£å°æ‡‰é¡¯å¡çš„é©…å‹•ã€‚")
        
        # ç‹€æ³ 2: æœ‰é©…å‹•ä½† PyTorch æŠ“ä¸åˆ° 
        else:
            print(f"â„¹ï¸  åµæ¸¬åˆ° NVIDIA é©…å‹•ç‰ˆæœ¬: {driver_version}")
            
            # æª¢æŸ¥ PyTorch æ˜¯å¦ç‚º CPU ç‰ˆæœ¬ (ç‰ˆæœ¬è™Ÿé€šå¸¸æœƒå¸¶æœ‰ +cpu)
            if "cpu" in torch.__version__:
                print("âŒ éŒ¯èª¤ï¼šä½ å®‰è£çš„æ˜¯ PyTorch [CPU ç‰ˆæœ¬]ã€‚")
                print("ğŸ’¡ å»ºè­°ï¼šè«‹ç§»é™¤ç›®å‰çš„ torch ä¸¦é‡æ–°å®‰è£ GPU ç‰ˆæœ¬ã€‚")
            else:
                # ç°¡å–®é‚è¼¯ï¼šå¦‚æœé©…å‹•ç‰ˆæœ¬ < 450ï¼Œé€šå¸¸ä¸æ”¯æ´è¼ƒæ–°çš„ CUDA 11+
                try:
                    major_v = float(driver_version.split('.')[0])
                    if major_v < 450:
                        print("âŒ éŒ¯èª¤ï¼šæ‚¨çš„ NVIDIA é©…å‹•ç‰ˆæœ¬éèˆŠã€‚")
                        print("ğŸ’¡ å»ºè­°ï¼šè«‹æ›´æ–°é¡¯å¡é©…å‹•ç¨‹å¼è‡³æœ€æ–°ç‰ˆæœ¬ã€‚")
                    else:
                        print("âŒ éŒ¯èª¤ï¼šPyTorch èˆ‡ CUDA ç’°å¢ƒé…ç½®ä¸åŒ¹é…ã€‚")
                        print("ğŸ’¡ å»ºè­°ï¼šå˜—è©¦æŒ‡å®šç‰ˆæœ¬å®‰è£ï¼Œä¾‹å¦‚ï¼š")
                        print("   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121")
                except:
                    print("âŒ éŒ¯èª¤ï¼šç„¡æ³•è­˜åˆ¥é©…å‹•èˆ‡ç’°å¢ƒçš„ç›¸å®¹æ€§ï¼Œå»ºè­°é‡æ–°é…ç½®ç’°å¢ƒã€‚")

    print("="*60)

if __name__ == "__main__":
    check_hardware()
